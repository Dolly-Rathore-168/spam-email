{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d7ec4f4-4b8f-4f14-a617-0a61246256d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d772388-5d3c-447c-b9c5-99cfdd2614db",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('spam.csv', quotechar='\"', on_bad_lines='skip')"
   ]
  },
  {
   "cell_type": "raw",
   "id": "51bead19-cad4-49f6-97d2-8f661e9eaf90",
   "metadata": {},
   "source": [
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7daccf9b-80a8-4249-aa05-d048d569b761",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ed0573d-3a51-4688-ba95-ebd6210ec848",
   "metadata": {},
   "outputs": [],
   "source": [
    "(5575,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6961bcc9-1b14-4441-9b84-18c6e425b8f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1. Data Cleaning\n",
    "#2. EDA\n",
    "#3. Text Preprocessing\n",
    "#4. Model building\n",
    "#5. Improvement \n",
    "#6. Website\n",
    "#7.Deploy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d63494a-0ec2-4eac-976a-ac4215bc75a2",
   "metadata": {},
   "source": [
    "##1. Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b9b80ea-2633-49b0-bb76-82bf6fb9502c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9c610cc-0b77-4cf2-870a-0cb2f7f2e9d2",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c69a8059-9a40-4119-9ec4-2488f462d216",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop last three cols\n",
    "cols_to_drop = ['Unnamed: 2', 'Unnamed: 3', 'Unnamed: 4']\n",
    "df.drop(columns=[col for col in cols_to_drop if col in df.columns], inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "487d84f4-0994-41b2-8919-173c92b8be9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "406fb9e7-70e9-4c8f-93c4-de305636775e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#renaming the cols\n",
    "df.rename(columns={'v1':'target','v2':'text'},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c23d14c7-6167-4ca9-8c0b-a44f96bc82a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16c17865-4cd8-43fd-a5a0-9f9868d81ef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "encoder = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4da1f60-1702-442e-bb85-411878123f6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.columns)\n",
    "df = pd.read_csv('spam.csv', sep='\\t', header=None, names=['label', 'text'])"
   ]
  },
  {
   "cell_type": "raw",
   "id": "99311cef-3d7e-4fd4-890b-b0c93da62435",
   "metadata": {},
   "source": [
    "print(df['label'].unique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99aed173-1e42-4e63-afb4-6ce57d1336a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df['label'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b964ff4-9d0c-42f0-b0b1-45530cbc7cf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['label_encoded'] = encoder.fit_transform(df['label'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c100a28e-1311-4ee7-b6ce-038790cfa84b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75483b42-6512-4702-ba48-dca172433b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "#missing values\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a78e68de-d7b2-4e2e-b08c-b527a17c5c69",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check for duplicate values\n",
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39ef2b45-ba17-4425-9811-69e6ac76660e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove duplicates\n",
    "df=df.drop_duplicates(keep='first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9ab4e41-fec2-4c3e-bd50-8d5fa8998a02",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.duplicated().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acadf99a-6c42-49b1-bdf1-76e6239f9cd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c75f2a56-e782-44e8-9c78-94177622da79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2076dd1e-7adc-4378-9fc6-e1e57c3677c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82f78859-42bc-42b3-a447-75c8370e2cc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['label'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b76a8e2-cfc1-4bf1-8b40-cc55afc1ba6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e6916d1-8bf1-4f3e-91c5-703bfe8504f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.pie(df['label'].value_counts(), labels=['ham', 'spam'], autopct=\"%0.2f%%\")\n",
    "plt.title(\"Distribution of Ham vs Spam\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7697888-e472-4403-9b62-54f6e6543b2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data is imbalanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8c120c9-66e4-4c25-b8b7-e1a6cd43d140",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7aa1626-adc2-4937-a3df-5d1ac29eaab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['num_characters']=df['text'].apply(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a00d59a1-8ca5-44ff-99bd-58e2757bf6fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ee95543-e65e-49da-96ca-ec0749543dd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#num of words\n",
    "nltk.download('punkt_tab')\n",
    "\n",
    "df['num_words'] = df['text'].fillna('').apply(lambda x: len(word_tokenize(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08d5457c-3155-44b2-a6d4-875f29b69ba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "df['num_words'] = df['text'].fillna('').apply(lambda x: len(word_tokenize(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aa622e3-0a89-4ece-9a51-d66c3e660e86",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2f9ebc3-cc2a-4178-ac41-2cfef3cf9c93",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "df['num_words'] = df['text'].fillna('').apply(lambda x: len(word_tokenize(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90f0ad01-5f11-4ea2-a8ab-5281e6c72d74",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize\n",
    "df['num_sentences'] = df['text'].fillna('').apply(lambda x: len(sent_tokenize(x)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f5c9a89-db83-4405-b242-6f72ee59abb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['num_character'] = df['text'].fillna('').apply(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d89e15a5-fe8e-4596-b984-ae6fbd52954b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['num_character','num_words','num_sentences']].describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b7dd2f2-fa64-440a-84e1-b026acaea7f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0748ab2-eeff-4b4f-9497-cfddf76410da",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9910da0-7e68-434e-aa5f-11dcec3fcea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['label'] == 0][['num_character', 'num_sentences', 'num_words']].describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aa28b5b-7974-43ff-8843-047218d8ab8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['label'] == 1][['num_character', 'num_sentences', 'num_words']].describe()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b39f599-ef4a-4023-83e6-668cf69f03db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de8b0b30-8c46-479f-abb8-3513f1680e44",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12e76901-56c8-43ad-9669-567a98108bba",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,6))\n",
    "\n",
    "# Histogram for label == 0 (e.g., real news)\n",
    "sns.histplot(df[df['label'] == 0]['num_characters'])\n",
    "\n",
    "# Histogram for label == 1 (e.g., fake news), in red\n",
    "sns.histplot(df[df['label'] == 1]['num_characters'], color='red')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1445c194-f6e7-45a3-8462-b41e2bbe30be",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,6))\n",
    "\n",
    "# Histogram for label == 0 (e.g., real news)\n",
    "sns.histplot(df[df['label'] == 0]['num_words'])\n",
    "\n",
    "# Histogram for label == 1 (e.g., fake news), in red\n",
    "sns.histplot(df[df['label'] == 1]['num_words'], color='red')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ad923a5-cdf0-4920-8c50-8f39c988a3c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e46ae915-03aa-4d2b-a26c-4e06040e0857",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(df, hue='label')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f85899f-5846-44c3-940a-256636cbfcfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.select_dtypes(include='number').columns)\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d57b3505-10e9-4a99-a0f0-72f23e05c397",
   "metadata": {},
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "sns.heatmap(df.corr(), annot=True, cmap='coolwarm')\n",
    "plt.title(\"Correlation Heatmap\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3cfd374-ca3f-47b5-93ca-68315aacc67f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c5ecf87-3cbf-4c0b-a205-a1c5bb87283d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tranform_text(text):\n",
    "    text=text.lower()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60fc0539-0aa5-4a31-812e-7decbbb8d02a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "import string\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ccf06f4-85ca-4af0-b7ca-5245d823a72f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "import string\n",
    "\n",
    "# Download stopwords if not already downloaded\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "ps = PorterStemmer()\n",
    "\n",
    "def transform_text(text):\n",
    "    text = text.lower()  # lowercase\n",
    "    text = nltk.word_tokenize(text)  # tokenization\n",
    "    \n",
    "    y = []\n",
    "    for word in text:\n",
    "        if word.isalnum():  # remove punctuation/special characters\n",
    "            y.append(word)\n",
    "    \n",
    "    text = y[:]\n",
    "    y.clear()\n",
    "    \n",
    "    for word in text:\n",
    "        if word not in stopwords.words('english'):\n",
    "            y.append(ps.stem(word))  # stemming and removing stopwords\n",
    "\n",
    "    return \" \".join(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66d03224-4974-4e6c-988b-6b776f434829",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "756f2f9a-4488-4cc8-bc89-667bfff40ebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_text('Hi How are you')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f3ea77e-fccb-40f7-b508-40bcb5f7e484",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[2000, 'text']  # based on index label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d287bab0-13d3-4636-a792-889bdbfe9646",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text'][100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "316747df-d795-4dc0-bbf2-d67eb564bfbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text'].iloc[2000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ddb259a-4e6a-452e-a421-bd680476c7af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "string.punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "953bc1bd-0572-4583-9c3b-2b8d31604bec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "ps = PorterStemmer()\n",
    "print(ps.stem('loving'))  # Output: love\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c45cf9e0-d1ff-4cee-a67d-ce88f83ab51d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Assume y is defined outside and reused\n",
    "y = []\n",
    "\n",
    "def transform_text(text):\n",
    "    text = text.lower().strip()\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "\n",
    "    # Clear y at the start\n",
    "    y.clear()\n",
    "\n",
    "    for word in tokens:\n",
    "        if word not in string.punctuation and word not in stopwords.words('english'):\n",
    "            y.append(word)\n",
    "\n",
    "    return y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79105123-f26f-46dc-b4b9-a3774334b472",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('spam.csv', encoding='latin-1', header=None, on_bad_lines='skip', engine='python')\n",
    "\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92aee519-35b6-4bcb-a531-d88371a77326",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install wordcloud\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84f48ec1-b4dc-49ab-8e9b-8936a942d425",
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud\n",
    "\n",
    "wc = WordCloud(width=800, height=400, min_font_size=10, background_color='white')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fc4f57c-5c8c-4ce7-8b06-018fabbadb49",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('spam.csv', encoding='latin-1', on_bad_lines='skip', engine='python')\n",
    "print(df.columns)\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eae1afac-6cd6-4e6e-94e5-429755a7bf0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Step 1: Load CSV without header (to avoid header issues)\n",
    "df = pd.read_csv('spam.csv', encoding='latin-1', header=None, on_bad_lines='skip', engine='python')\n",
    "\n",
    "# Step 2: Inspect the first 5 rows to confirm data layout\n",
    "print(df.head())\n",
    "\n",
    "# Step 3: Assuming first column is label, second is text\n",
    "df = df[[0, 1]]\n",
    "df.columns = ['label', 'text']\n",
    "\n",
    "# Step 4: Simple text transformation function\n",
    "def transform_text(text):\n",
    "    return str(text).lower().split()\n",
    "\n",
    "# Step 5: Apply transform_text\n",
    "df['transformed_text'] = df['text'].apply(transform_text)\n",
    "df['transformed_text'] = df['transformed_text'].apply(lambda tokens: \" \".join(tokens))\n",
    "\n",
    "# Step 6: Create WordCloud object\n",
    "wc = WordCloud(width=500, height=500, min_font_size=10, background_color='white')\n",
    "\n",
    "# Step 7: Generate WordCloud only\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aefa229-34dd-49a0-ad7f-1c87b09759df",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.columns)\n",
    "print(df.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddb6926e-889b-4e8f-a6a2-4e5a9b4c448c",
   "metadata": {},
   "outputs": [],
   "source": [
    "spam_wc = wc.generate(df[df['label'] == 'spam']['transformed_text'].str.cat(sep=\" \"))\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.imshow(spam_wc, interpolation='bilinear')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7d4dbea-5e79-4164-a57a-fa445b7a170b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(spam_wc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ae7a047-72d7-465f-8c96-431c7c38b455",
   "metadata": {},
   "outputs": [],
   "source": [
    "spam_corpus = []\n",
    "for msg in df[df['label'] == 'spam']['transformed_text'].tolist():\n",
    "    print(msg)\n",
    "    for word in msg.split():\n",
    "        spam_corpus.append(word)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62b27911-891b-4a57-a4d2-e64f76794e62",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0c404c2-9e94-43fa-b667-cb7333b862c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(spam_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "958793fc-75cd-4436-add6-b2765979917f",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_30_words = Counter(spam_corpus).most_common(30)\n",
    "df_top_words = pd.DataFrame(top_30_words, columns=['word', 'count'])\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.barplot(data=df_top_words, x='count', y='word', hue='word', palette='viridis', legend=False)\n",
    "plt.title('Top 30 Most Common Words in Spam Corpus')\n",
    "plt.xlabel('Count')\n",
    "plt.ylabel('Word')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e1ce6c4-adfc-4465-80d4-72dd9cb28e24",
   "metadata": {},
   "outputs": [],
   "source": [
    "ham_corpus = []\n",
    "for msg in df[df['label'] == 'ham']['transformed_text'].tolist():\n",
    "    for word in msg.split():\n",
    "        ham_corpus.append(word)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1015f82-3063-486e-8a36-4dbde918e7c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90ac2e67-6bf5-45b4-8776-c00a3c136623",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10adbae6-e2ba-4307-b154-e475358fd0c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "cv = CountVectorizer()\n",
    "tdif = TfidfVectorizer(max_features=3000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "922d4022-f458-46f9-bf83-30f89b0f36c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer()\n",
    "\n",
    "# Now fit and transform your text data\n",
    "X = tfidf.fit_transform(df['transformed_text']).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4032455-35b0-436c-8f82-4f6b1dc1f2a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.hstack((X,df['num_characters'].values.reshape(-1,1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "878f2b87-efe3-43dc-9130-03a7dc61601a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04313cd3-3ec3-4af5-b5a0-384de3802459",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "X = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40b3e78b-5d0a-49e3-8f31-10cc2f517db3",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['label'].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ce3812d-59bf-433f-8496-26895652a25c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "416666fc-566b-45f9-ba61-bcd16ed0991e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1115c01-2ae1-4fe9-bf7c-e0d09f466bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43247356-1b06-441b-b10e-ff80aae3ae33",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "cv = CountVectorizer()\n",
    "X = cv.fit_transform(df['transformed_text']).toarray()\n",
    "\n",
    "y = df['label'].values  # Replace 'label' if your target column is named differently\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=2\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1778e036-c2e3-4c33-8fdc-0c16f07995e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB,MultinomialNB,BernoulliNB\n",
    "from sklearn.metrics import accuracy_score,confusion_matrix,precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9dc152e-c30e-4a98-95bd-7a2b5dff6db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "gnb=GaussianNB()\n",
    "gnb=MultinomialNB()\n",
    "bnb=BernoulliNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e50e7880-869e-4343-a6ab-959ba722c2f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "gnb.fit(X_train, Y_train)\n",
    "y_pred1 = gnb.predict(X_test)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(Y_test, y_pred1))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(Y_test, y_pred1))\n",
    "print(\"Classification Report:\\n\", classification_report(Y_test, y_pred1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa4c1a4a-8312-408c-8fb5-3d98bf2555ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "# Create the model\n",
    "mnb = MultinomialNB()\n",
    "\n",
    "# Fit the model\n",
    "mnb.fit(X_train, Y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred1 = mnb.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(Y_test, y_pred1))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(Y_test, y_pred1))\n",
    "print(\"Classification Report:\\n\", classification_report(Y_test, y_pred1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "898e5d27-6568-4200-9da8-83f751de25f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tfidf --> MNB\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95851472-9d0c-4829-a03d-905d87b9665a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier, ExtraTreeClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, BaggingClassifier, GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdd1cb50-c7a8-4639-94e1-6d1b3e1e73d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "svc = SVC(kernel='sigmoid', gamma=1.0)  # Corrected kernel name from 'Signoid' to 'sigmoid'\n",
    "knc = KNeighborsClassifier()\n",
    "mnb = MultinomialNB()\n",
    "\n",
    "S = 5  # Assuming S is predefined as the desired max depth\n",
    "dtc = DecisionTreeClassifier(max_depth=S)\n",
    "\n",
    "lrc = LogisticRegression(solver='liblinear', penalty='l1')  # Corrected penalty from '11' to 'l1'\n",
    "\n",
    "rfc = RandomForestClassifier(n_estimators=50, random_state=2)  # Fixed typo: RandonForestClassifier â†’ RandomForestClassifier\n",
    "\n",
    "abc = AdaBoostClassifier(n_estimators=50, random_state=2)\n",
    "bc = BaggingClassifier(n_estimators=50, random_state=2)\n",
    "etc = ExtraTreeClassifier()  # ExtraTreeClassifier does not have n_estimators; itâ€™s a single tree\n",
    "\n",
    "gbdt = GradientBoostingClassifier(n_estimators=50, random_state=2)\n",
    "xgb = XGBClassifier(n_estimators=50, random_state=2)  # Fixed typo: n_estimator â†’ n_estimators\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deb38692-8ab9-4b26-a1d0-ff2551875a11",
   "metadata": {},
   "outputs": [],
   "source": [
    "clfs = {\n",
    "    'SVC': svc,\n",
    "    'KNeighbors': knc,\n",
    "    'MultinomialNB': mnb,\n",
    "    'DecisionTree': dtc,\n",
    "    'LogisticRegression': lrc,\n",
    "    'RandomForest': rfc,\n",
    "    'AdaBoost': abc,\n",
    "    'Bagging': bc,\n",
    "    'ExtraTree': etc,\n",
    "    'GradientBoosting': gbdt,\n",
    "    'XGBoost': xgb\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f719127-6080-47f6-a9af-11b571a853ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score\n",
    "\n",
    "def train_classifier(clf, X_train, y_train, X_test, y_test):\n",
    "    clf.fit(X_train, y_train)  # Train on training data\n",
    "    y_pred = clf.predict(X_test)  # Predict on test data\n",
    "\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, average='binary')  # or 'macro'/'weighted' depending on your problem\n",
    "\n",
    "    return accuracy, precision\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58bc8ee2-8ae0-47c7-879c-88b6b8cd3241",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, precision_score\n",
    "\n",
    "# Load example dataset\n",
    "data = load_iris()\n",
    "X = data.data\n",
    "y = data.target\n",
    "\n",
    "# For simplicity, convert to binary classification (e.g., class 0 vs rest)\n",
    "import numpy as np\n",
    "y_binary = np.where(y == 0, 1, 0)  # class 0 is positive class (1), others negative (0)\n",
    "\n",
    "# Split data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_binary, test_size=0.3, random_state=42)\n",
    "\n",
    "# Define the function (as before)\n",
    "def train_classifier(clf, X_train, y_train, X_test, y_test):\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    return accuracy, precision\n",
    "\n",
    "# Create the classifier instance\n",
    "svc = SVC()\n",
    "\n",
    "# Call the function\n",
    "accuracy, precision = train_classifier(svc, X_train, y_train, X_test, y_test)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Precision: {precision}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9243fa4-d1fd-46a8-a749-a679ea99ed2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_scores = []\n",
    "precision_scores = []\n",
    "\n",
    "for name, clf in clfs.items():\n",
    "    accuracy, precision = train_classifier(clf, X_train, y_train, X_test, y_test)\n",
    "    accuracy_scores.append((name, accuracy))\n",
    "    precision_scores.append((name, precision))\n",
    "\n",
    "# Print the results\n",
    "for name, acc in accuracy_scores:\n",
    "    print(f\"{name} Accuracy: {acc}\")\n",
    "\n",
    "for name, prec in precision_scores:\n",
    "    print(f\"{name} Precision: {prec}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef6847b1-eb50-43a2-9b06-5bb04e2a8318",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score\n",
    "\n",
    "accuracy_scores = []\n",
    "precision_scores = []\n",
    "\n",
    "for name, clf in clfs.items():\n",
    "    try:\n",
    "        current_accuracy, current_precision = train_classifier(clf, X_train, y_train, X_test, y_test)\n",
    "        accuracy_scores.append((name, current_accuracy))\n",
    "        precision_scores.append((name, current_precision))\n",
    "    except Exception as e:\n",
    "        print(f\"Error training {name}: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe48c586-892b-416e-916d-76afd63e567e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_classifier(clf, X_train, y_train, X_test, y_test):\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    \n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, zero_division=0)  # prevents precision warning\n",
    "\n",
    "    return accuracy, precision\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb6b5db1-61a1-4365-86c6-406fdec44a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Combine into one DataFrame\n",
    "performance_df = pd.DataFrame({\n",
    "    'Algorithms': [name for name, _ in accuracy_scores],\n",
    "    'Accuracy': [score for _, score in accuracy_scores],\n",
    "    'Precision': [score for _, score in precision_scores]\n",
    "})\n",
    "\n",
    "# Sort by Precision descending\n",
    "performance_df = performance_df.sort_values('Precision', ascending=False)\n",
    "\n",
    "print(performance_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ded71fea-4b36-415e-8a27-47ef7da5a162",
   "metadata": {},
   "outputs": [],
   "source": [
    "performance_df = pd.DataFrame({\n",
    "    'Algorithm': [name for name, _ in accuracy_scores],\n",
    "    'Accuracy': [score for _, score in accuracy_scores],\n",
    "    'Precision': [score for _, score in precision_scores]\n",
    "})\n",
    "performance_df = performance_df.sort_values('Precision', ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37c35540-5d8d-422f-a9a1-cc29e3eeffec",
   "metadata": {},
   "outputs": [],
   "source": [
    "performance_df1 = pd.melt(performance_df, id_vars='Algorithm', \n",
    "                          var_name='Metric', value_name='Score')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44283733-ef7f-46ee-9c16-3e51ec4488f4",
   "metadata": {},
   "source": [
    "performance_df1 = pd.melt(performance_df, id_vars='Algorithms', \n",
    "                          var_name='Metric', value_name='Score')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d521b05-4c27-40e9-9053-a5e0bdaa8e09",
   "metadata": {},
   "outputs": [],
   "source": [
    "performance_df.merge(temp_df,on='Algorithm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6e79a75-b270-4fed-933a-6d7d601bfc06",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sns.catplot(x='Algorithm', y='Score', hue='Metric',\n",
    "            data=performance_df1, kind='bar', height=5)\n",
    "\n",
    "plt.ylim(0.5, 1.0)\n",
    "plt.xticks(rotation='vertical')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0475bfd1-9a93-44ae-98f9-2e3bc1ff178c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model improve\n",
    "# 1.change the max_featutures parameter of tfidf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2b0454d-3c24-4837-b8b5-03d66c208f28",
   "metadata": {},
   "source": [
    "temp_df = pd.DataFrame({\n",
    "    'Algorithm': list(clfs.keys()),\n",
    "    'Accuracy_max_ft_3000': [score for _, score in accuracy_scores],\n",
    "    'Precision_max': [score for _, score in precision_scores]\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "321238c9-b747-4953-ad57-b7e40ae8d927",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df = pd.DataFrame({\n",
    "    'Algorithm': [name for name, _ in accuracy_scores],\n",
    "    'Accuracy_max_ft_3000': [score for _, score in accuracy_scores],\n",
    "    'Precision_max_ft_3000': [score for _, score in precision_scores]\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18e24ce9-e4c6-42a3-a4ab-88f823a47543",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Example classifiers dictionary\n",
    "clfs = {\n",
    "    'SVM': SVC(),\n",
    "    'RandomForest': RandomForestClassifier(),\n",
    "    'KNN': KNeighborsClassifier()\n",
    "}\n",
    "\n",
    "# Assume X and y are your features and labels loaded already\n",
    "# For example:\n",
    "# X = your_features_dataframe_or_array\n",
    "# y = your_label_series_or_array with values like 'ham' and 'spam'\n",
    "\n",
    "# 1. Encode labels to numeric\n",
    "le = LabelEncoder()\n",
    "y_encoded = le.fit_transform(y)  # Converts 'ham'/'spam' to 0/1\n",
    "\n",
    "# 2. Split the dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y_encoded, test_size=0.2, random_state=2\n",
    ")\n",
    "\n",
    "# 3. Scale features\n",
    "scaler = MinMaxScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# 4. Function to train classifier and compute metrics\n",
    "def train_classifier(clf, X_train, y_train, X_test, y_test):\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, zero_division=0)\n",
    "    return accuracy, precision\n",
    "\n",
    "# 5. Train classifiers and collect metrics\n",
    "accuracy_scores = []\n",
    "precision_scores = []\n",
    "\n",
    "for name, clf in clfs.items():\n",
    "    acc, prec = train_classifier(clf, X_train, y_train, X_test, y_test)\n",
    "    accuracy_scores.append((name, acc))\n",
    "    precision_scores.append((name, prec))\n",
    "\n",
    "# 6. Create a DataFrame with the results\n",
    "performance_df = pd.DataFrame({\n",
    "    'Algorithm': [name for name, _ in accuracy_scores],\n",
    "    'Accuracy': [score for _, score in accuracy_scores],\n",
    "    'Precision': [score for _, score in precision_scores]\n",
    "})\n",
    "\n",
    "print(performance_df)\n",
    "\n",
    "# 7. Example of merging if you have another DataFrame new_df\n",
    "# Assuming new_df also has 'Algorithm' column and you want to merge:\n",
    "# new_df_scaled = new_df.merge(performance_df, on='Algorithm')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c862db7-3978-4929-92a5-dbc6e2807442",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = pd.DataFrame({\n",
    "    'Algorithm': ['SVM', 'RandomForest', 'KNN'],\n",
    "    'SomeMetric': [0.82, 0.89, 0.78]\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d145a1d1-750a-4134-aece-93931278aff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df_scaled = performance_df.merge(temp_df, on='Algorithm')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9a1a5c7-6e39-4679-a59f-344cc33e8a5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df_scaled = new_df.merge(temp_df, on='Algorithm')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91388b31-f33a-418e-8305-ac30b452e936",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "381ef336-8352-467d-8596-92de1158d1b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# voting classifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.tree import ExtraTreeClassifier  # Note: this is a single tree classifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "svc = SVC(kernel='sigmoid', gamma=1.0, probability=True)  # fixed 'signoid' typo\n",
    "mnb = MultinomialNB()\n",
    "etc = ExtraTreeClassifier()  # You need to specify n_estimators only for ensemble, not ExtraTreeClassifier\n",
    "\n",
    "voting_clf = VotingClassifier(\n",
    "    estimators=[('svc', svc), ('mnb', mnb), ('etc', etc)],\n",
    "    voting='soft'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88084903-d702-4558-b418-92b6ba4f769e",
   "metadata": {},
   "outputs": [],
   "source": [
    "voting_clf.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce15cf9e-649f-4a21-b73c-a256d374ec3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the voting classifier\n",
    "voting_clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict on test set\n",
    "y_pred = voting_clf.predict(X_test)\n",
    "\n",
    "# Evaluate accuracy and precision\n",
    "from sklearn.metrics import accuracy_score, precision_score\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "\n",
    "print(f\"Voting Classifier Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Voting Classifier Precision: {precision:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34e3adef-5b88-488f-ba5a-87011b65be36",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le = LabelEncoder()\n",
    "y_train_enc = le.fit_transform(y_train)\n",
    "y_test_enc = le.transform(y_test)\n",
    "\n",
    "voting_clf.fit(X_train, y_train_enc)\n",
    "y_pred = voting_clf.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6430c5ef-5907-49f5-b926-f3ad16e5038d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define individual classifiers\n",
    "svc = SVC(kernel='sigmoid', gamma=1.0, probability=True)\n",
    "mnb = MultinomialNB()\n",
    "etc = ExtraTreesClassifier(n_estimators=50, random_state=2)\n",
    "\n",
    "# Define the soft voting classifier\n",
    "voting_clf = VotingClassifier(\n",
    "    estimators=[\n",
    "        ('svm', svc),\n",
    "        ('nb', mnb),\n",
    "        ('et', etc)\n",
    "    ],\n",
    "    voting='soft'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "055025c8-e072-4319-b97f-0632e5088f7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ðŸ‘‰ Then make predictions\n",
    "y_pred = voting_clf.predict(X_test)\n",
    "\n",
    "# ðŸ‘‰ Evaluate\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Precision:\", precision_score(y_test, y_pred, pos_label=1))\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "9e60329c-33f3-4769-bd07-0351ccbf80a7",
   "metadata": {},
   "source": [
    "from sklearn.ensemble import VotingClassifier, StackingClassifier, RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.tree import ExtraTreeClassifier\n",
    "\n",
    "# Define individual estimators\n",
    "svc = SVC(kernel='sigmoid', gamma=1.0, probability=True)\n",
    "mnb = MultinomialNB()\n",
    "etc = ExtraTreeClassifier()\n",
    "\n",
    "estimators = [('svm', svc), ('nb', mnb), ('et', etc)]\n",
    "\n",
    "# If you want a VotingClassifier (no final_estimator param)\n",
    "voting_clf = VotingClassifier(estimators=estimators, voting='soft')\n",
    "\n",
    "# If you want to use a final_estimator, use StackingClassifier\n",
    "stacking_clf = StackingClassifier(\n",
    "    estimators=estimators,\n",
    "    final_estimator=RandomForestClassifier(),\n",
    "    passthrough=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d2b45df-b982-4940-8905-7078db34d938",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import StackingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf6bc311-1b36-45ca-b127-0b2a6cffdef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import StackingClassifier, RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.tree import ExtraTreeClassifier\n",
    "\n",
    "# Define base classifiers\n",
    "svc = SVC(kernel='sigmoid', gamma=1.0, probability=True)\n",
    "mnb = MultinomialNB()\n",
    "etc = ExtraTreeClassifier()\n",
    "\n",
    "estimators = [('svm', svc), ('nb', mnb), ('et', etc)]\n",
    "\n",
    "# Define the final estimator\n",
    "final_estimator = RandomForestClassifier()\n",
    "\n",
    "# Initialize the stacking classifier\n",
    "clf = StackingClassifier(estimators=estimators, final_estimator=final_estimator)\n",
    "\n",
    "# Then fit and predict as usual:\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b122749d-664b-419d-b685-29070b3d5543",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Evaluate\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Precision:\", precision_score(y_test, y_pred, pos_label=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42100caf-bd74-4c43-b095-5ec1e272a925",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Save the trained model to a file\n",
    "with open('stacking_model.pkl', 'wb') as f:\n",
    "    pickle.dump(clf, f)\n",
    "\n",
    "# Later on, load the model from the file\n",
    "with open('stacking_model.pkl', 'rb') as f:\n",
    "    loaded_clf = pickle.load(f)\n",
    "\n",
    "# Now you can use loaded_clf to predict\n",
    "y_pred_loaded = loaded_clf.predict(X_test)\n",
    "print(\"Accuracy with loaded model:\", accuracy_score(y_test, y_pred_loaded))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a16d75f0-03cd-4c43-ac98-e9cd8ab631ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "import pickle\n",
    "\n",
    "# 1. Create and train your vectorizer and model (example)\n",
    "tfidf = TfidfVectorizer()\n",
    "X_train = [\"some text data\", \"another example\"]  # your training data\n",
    "y_train = [0, 1]  # labels\n",
    "\n",
    "X_train_tfidf = tfidf.fit_transform(X_train)\n",
    "\n",
    "mnb = MultinomialNB()\n",
    "mnb.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# 2. Save vectorizer and model\n",
    "with open('vectorizer.pkl', 'wb') as f:\n",
    "    pickle.dump(tfidf, f)\n",
    "\n",
    "with open('model.pkl', 'wb') as f:\n",
    "    pickle.dump(mnb, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4936cd6e-bfa1-46fd-8c46-022cc4004ed0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
