# app.py â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
import streamlit as st
import pickle
import re
import nltk
from nltk.corpus import stopwords
from nltk.stem.porter import PorterStemmer

# 1ï¸âƒ£  Page settings â€“ must be FIRST Streamlit call
st.set_page_config(page_title="Spam Classifier", page_icon="ğŸš«")

# 2ï¸âƒ£  Load NLTK resources once and cache them
@st.cache_resource
def load_nltk():
    nltk.download("stopwords")
    nltk.download("punkt")
    return set(stopwords.words("english")), PorterStemmer()

STOP_WORDS, STEMMER = load_nltk()

# 3ï¸âƒ£  Load the trained vectorizer and model once
@st.cache_resource
def load_artifacts():
    with open("vectorizer.pkl", "rb") as vf:
        vectorizer = pickle.load(vf)
    with open("model.pkl", "rb") as mf:
        model = pickle.load(mf)
    return vectorizer, model

VECTORIZER, MODEL = load_artifacts()

# 4ï¸âƒ£  Text-preprocessing identical to your training pipeline
def transform_text(text: str) -> str:
    text = re.sub(r"[^a-zA-Z]", " ", text).lower()
    tokens = nltk.word_tokenize(text)
    tokens = [STEMMER.stem(t) for t in tokens if t not in STOP_WORDS]
    return " ".join(tokens)

# 5ï¸âƒ£  Streamlit UI
st.title("ğŸ“§ Email / SMS Spam Classifier")

user_msg = st.text_area("âœï¸ Enter a message:")

if st.button("Predict"):
    if not user_msg.strip():
        st.warning("âš ï¸  Please enter some text.")
    else:
        cleaned = transform_text(user_msg)
        vector = VECTORIZER.transform([cleaned])
        pred = MODEL.predict(vector)[0]

        if pred == 1:
            st.error("ğŸš« Spam")
        else:
            st.success("âœ… Not Spam")
